'use client';

import React, { useState, useRef, useCallback } from 'react';
import { Button } from '@/components/ui/Button';
import { cn } from '@/lib/utils';
import { storageService } from '@/lib/cloudbase/storage';

interface ProfessionalVoiceInputProps {
  onTranscriptionComplete: (text: string) => void;
  className?: string;
}

export function ProfessionalVoiceInput({ onTranscriptionComplete, className }: ProfessionalVoiceInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isUploading, setIsUploading] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [uploadProgress, setUploadProgress] = useState(0);
  const [error, setError] = useState<string>('');
  const [transcriptText, setTranscriptText] = useState<string>('');
  const [confidence, setConfidence] = useState<number>(0);
  const [showResults, setShowResults] = useState<boolean>(false); // æ§åˆ¶ç»“æœæ¡†æ˜¾ç¤º
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const fileInputRef = useRef<HTMLInputElement | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      setError('');
      setTranscriptText('');
      setConfidence(0);
      setRealtimeText('');
      setConfirmedText('');
      setShowResults(false);
      // é‡ç½®refçŠ¶æ€
      confirmedTextRef.current = '';
      realtimeTextRef.current = '';
      // é‡ç½®å»é‡é›†åˆ
      processedSentencesRef.current.clear();
      
      // é…ç½®éŸ³é¢‘å‚æ•°ä»¥ç¬¦åˆDashScopeè¦æ±‚
      const constraints = {
        audio: {
          sampleRate: 16000,      // 16kHzé‡‡æ ·ç‡
          channelCount: 1,        // å•å£°é“
          echoCancellation: true, // å›éŸ³æ¶ˆé™¤
          noiseSuppression: true, // å™ªéŸ³æŠ‘åˆ¶
          autoGainControl: true   // è‡ªåŠ¨å¢ç›Šæ§åˆ¶
        }
      };
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      
      // ä½¿ç”¨Web Audio APIè·å–PCMæ•°æ®
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000
      });
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (event) => {
        const inputBuffer = event.inputBuffer;
        const inputData = inputBuffer.getChannelData(0); // è·å–å•å£°é“PCMæ•°æ®
        
        // è½¬æ¢ä¸º16ä½PCM
        const pcmData = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcmData[i] = Math.max(-32768, Math.min(32767, Math.floor(inputData[i] * 32768)));
        }
        
        console.log('ğŸµ è·å–PCMéŸ³é¢‘æ•°æ®:', pcmData.byteLength, 'bytes');
        sendAudioToWebSocket(pcmData.buffer);
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      
      // ä¿å­˜å¼•ç”¨ç”¨äºæ¸…ç†
      audioContextRef.current = audioContext;
      processorRef.current = processor;
      
      // åŒæ—¶ä¿ç•™MediaRecorderç”¨äºå½•éŸ³ç»“æŸå¤„ç†
      let mimeType = 'audio/webm';
      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
          console.log('ğŸ’¾ MediaRecorderæ•°æ®æ”¶é›†:', event.data.size, 'bytes (ç”¨äºå½•éŸ³æ–‡ä»¶)');
        }
      };
      
      mediaRecorder.onstop = async () => {
        // æ¸…ç†Web Audio APIèµ„æº
        if (processorRef.current) {
          processorRef.current.disconnect();
          processorRef.current = null;
        }
        if (audioContextRef.current) {
          audioContextRef.current.close();
          audioContextRef.current = null;
        }
        
        const audioBlob = new Blob(chunksRef.current, { type: mimeType });
        await processRealtimeAudio(audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start(1000); // æ¯ç§’æ”¶é›†ä¸€æ¬¡éŸ³é¢‘æ•°æ®ç”¨äºå®æ—¶ä¼ è¾“
      setIsRecording(true);
      setRecordingTime(0);
      
      // å¯åŠ¨WebSocketå®æ—¶è¯†åˆ«
      await startRealtimeRecognition();
      
      // å¼€å§‹è®¡æ—¶
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
    } catch (err) {
      setError('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
      console.error('Error accessing microphone:', err);
    }
  }, []);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
  }, [isRecording]);

  // å®æ—¶è¯­éŸ³è¯†åˆ«WebSocketè¿æ¥
  const wsRef = useRef<WebSocket | null>(null);
  const [realtimeText, setRealtimeText] = useState<string>(''); // å½“å‰æ­£åœ¨è¯†åˆ«çš„æ–‡å­—ï¼ˆä¼šè¢«ä¿®æ­£ï¼‰
  const [confirmedText, setConfirmedText] = useState<string>(''); // å·²ç¡®è®¤çš„æ–‡å­—ï¼ˆç´¯ç§¯ä¿å­˜ï¼‰
  const [dashscopeReady, setDashscopeReady] = useState<boolean>(false);
  const dashscopeReadyRef = useRef<boolean>(false); // ä½¿ç”¨refç¡®ä¿ç«‹å³å¯ç”¨
  const currentTaskIdRef = useRef<string>(''); // ä½¿ç”¨refç¡®ä¿ç«‹å³å¯ç”¨
  
  // ä½¿ç”¨refæ¥ç«‹å³å­˜å‚¨è¯†åˆ«ç»“æœï¼Œé¿å…ReactçŠ¶æ€æ›´æ–°å»¶è¿Ÿé—®é¢˜
  const confirmedTextRef = useRef<string>('');
  const realtimeTextRef = useRef<string>('');
  
  // ç”¨äºå»é‡çš„ref - å­˜å‚¨å·²ç»å¤„ç†è¿‡çš„å¥å­
  const processedSentencesRef = useRef<Set<string>>(new Set());

  // çœŸæ­£çš„WebSocketå®æ—¶è¯†åˆ«
  const startRealtimeRecognition = async () => {
    try {
      console.log('ğŸŒ å¯åŠ¨WebSocketå®æ—¶è¯­éŸ³è¯†åˆ«');
      
      // è¿æ¥åˆ°æœ¬åœ°WebSocketä»£ç†æœåŠ¡å™¨
      const proxyUrl = 'ws://localhost:8080/ws-proxy';
      console.log('ğŸ”— è¿æ¥åˆ°WebSocketä»£ç†:', proxyUrl);
      
      const ws = new WebSocket(proxyUrl);
      wsRef.current = ws;
      
      ws.onopen = () => {
        console.log('âœ… WebSocketä»£ç†è¿æ¥å·²å»ºç«‹ï¼Œç­‰å¾…DashScopeè¿æ¥...');
      };
      
      ws.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data);
          console.log('ğŸ“¡ æ”¶åˆ°ä»£ç†æ¶ˆæ¯:', message);
          
          if (message.type === 'proxy-connected') {
            console.log('âœ… DashScopeè¿æ¥å·²å»ºç«‹ï¼Œå‘é€åˆå§‹åŒ–æ¶ˆæ¯');
            
            // å‘é€DashScopeæ ‡å‡†åˆå§‹åŒ–æ¶ˆæ¯
            const taskId = `voice-${Date.now()}-${Math.random().toString(36).substring(7)}`;
            currentTaskIdRef.current = taskId;
            
            const initMessage = {
              header: {
                action: 'run-task',
                streaming: 'duplex',
                task_id: taskId
              },
              payload: {
                model: 'paraformer-realtime-v2',
                task_group: 'audio',
                task: 'asr',
                function: 'recognition',
                input: {
                  audio_encoding: 'pcm',
                  sample_rate: 16000,
                  format: 'pcm'
                },
                parameters: {
                  language_hints: ['zh'],
                  max_sentence_silence: 800, // å¥å­é—´æœ€å¤§é™é»˜æ—¶é—´(ms)ï¼Œæ§åˆ¶å¥å­åˆ†å‰²
                  enable_words: true, // å¼€å¯è¯çº§åˆ«æ—¶é—´æˆ³
                  enable_punctuation_prediction: true, // å¼€å¯æ ‡ç‚¹ç¬¦å·é¢„æµ‹
                  enable_inverse_text_normalization: true // å¼€å¯é€†æ–‡æœ¬æ­£è§„åŒ–
                }
              }
            };
            ws.send(JSON.stringify(initMessage));
            
          } else if (message.type === 'proxy-error') {
            console.error('âŒ ä»£ç†é”™è¯¯:', message.error);
            throw new Error(`WebSocketä»£ç†é”™è¯¯: ${message.error}`);
            
          } else if (message.type === 'proxy-closed') {
            console.log('ğŸ”Œ DashScopeè¿æ¥å·²å…³é—­');
            
          } else {
            // å¤„ç†DashScope WebSocketå“åº”æ ¼å¼
            console.log('ğŸ“¨ DashScopeæ¶ˆæ¯è¯¦æƒ…:', {
              event: message.header?.event,
              header: message.header,
              hasPayload: !!message.payload,
              hasOutput: !!(message.payload && message.payload.output),
              hasSentence: !!(message.payload && message.payload.output && message.payload.output.sentence),
              fullMessage: message
            });
            
            if (message.header && message.header.event === 'task-started') {
              console.log('ğŸ¯ DashScopeä»»åŠ¡å·²å¯åŠ¨ï¼Œç°åœ¨å¯ä»¥å‘é€éŸ³é¢‘æ•°æ®');
              setDashscopeReady(true);
              dashscopeReadyRef.current = true; // ç«‹å³è®¾ç½®refçŠ¶æ€
            }
            
            if (message.payload && message.payload.output) {
              const output = message.payload.output;
              
              // å¤„ç†å¥å­çº§è¯†åˆ«ç»“æœ
              if (output.sentence && output.sentence.text) {
                const sentence = output.sentence;
                console.log('ğŸ“¡ æ”¶åˆ°å¥å­æ•°æ®:', JSON.stringify(sentence, null, 2));
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæ•´å¥å­ï¼ˆå¿…é¡»åŒæ—¶æ»¡è¶³ï¼šend_timeä¸ä¸ºnull ä¸” sentence_endä¸ºtrueï¼‰
                const isFinalSentence = sentence.end_time !== null && sentence.sentence_end === true;
                console.log('ğŸ” å¥å­çŠ¶æ€:', {
                  text: sentence.text,
                  begin_time: sentence.begin_time,
                  end_time: sentence.end_time,
                  sentence_end: sentence.sentence_end,
                  isFinal: isFinalSentence
                });
                
                if (isFinalSentence) {
                  // ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œé¿å…é‡å¤å¤„ç†åŒä¸€ä¸ªå¥å­
                  const sentenceKey = `${sentence.begin_time}-${sentence.end_time}`;
                  const sentenceText = sentence.text.trim();
                  
                  if (!processedSentencesRef.current.has(sentenceKey) && sentenceText) {
                    // å·²ç¡®è®¤çš„å¥å­ï¼Œç´¯ç§¯åˆ°ç¡®è®¤æ–‡å­—ä¸­
                    processedSentencesRef.current.add(sentenceKey);
                    setConfirmedText(prev => {
                      const newConfirmed = prev + sentenceText;
                      confirmedTextRef.current = newConfirmed; // ç«‹å³æ›´æ–°ref
                      console.log('âœ… ç¡®è®¤å¥å­:', sentenceText);
                      console.log('ğŸ”‘ å¥å­æ ‡è¯†:', sentenceKey);
                      console.log('ğŸ“ ç´¯ç§¯ç¡®è®¤æ–‡å­—:', newConfirmed);
                      return newConfirmed;
                    });
                    setRealtimeText(confirmedTextRef.current); // æ˜¾ç¤ºå·²ç¡®è®¤çš„æ–‡å­—
                    realtimeTextRef.current = confirmedTextRef.current;
                  } else {
                    console.log('âš ï¸ é‡å¤å¥å­ï¼Œè·³è¿‡:', sentenceText, 'æ ‡è¯†:', sentenceKey);
                  }
                } else {
                  // ä¸­é—´è¯†åˆ«ç»“æœï¼Œæ˜¾ç¤ºä½†ä¸ç´¯ç§¯
                  // å®æ—¶æ–‡å­—æ˜¾ç¤ºï¼šå·²ç¡®è®¤æ–‡å­— + å½“å‰ä¸­é—´è¯†åˆ«æ–‡å­—
                  const currentText = sentence.text.trim();
                  const fullRealtimeText = confirmedTextRef.current + currentText;
                  setRealtimeText(fullRealtimeText);
                  realtimeTextRef.current = fullRealtimeText; // ç«‹å³æ›´æ–°ref
                  console.log('ğŸ¯ ä¸­é—´è¯†åˆ«:', currentText);
                  console.log('ğŸ” æ˜¾ç¤ºæ–‡å­—:', fullRealtimeText);
                }
              }
              
              // å¤„ç†å®Œæ•´è½¬å½•ç»“æœï¼ˆé€šå¸¸åœ¨ç»“æŸæ—¶å‘é€ï¼‰
              if (output.transcription) {
                const transcriptionText = output.transcription.trim();
                console.log('ğŸ¯ æ”¶åˆ°å®Œæ•´è½¬å½•:', transcriptionText);
                console.log('ğŸ” å½“å‰å·²ç¡®è®¤æ–‡å­—:', confirmedTextRef.current);
                
                // æ£€æŸ¥å®Œæ•´è½¬å½•æ˜¯å¦ä¸å·²ç¡®è®¤æ–‡å­—é‡å¤
                // å¦‚æœå®Œæ•´è½¬å½•å°±æ˜¯å½“å‰å·²ç¡®è®¤æ–‡å­—ï¼Œåˆ™è·³è¿‡
                if (transcriptionText && transcriptionText !== confirmedTextRef.current.trim()) {
                  // å¦‚æœå®Œæ•´è½¬å½•åŒ…å«äº†å·²ç¡®è®¤æ–‡å­—ï¼Œåªæ·»åŠ æ–°å¢éƒ¨åˆ†
                  let textToAdd = transcriptionText;
                  if (confirmedTextRef.current.trim() && transcriptionText.startsWith(confirmedTextRef.current.trim())) {
                    textToAdd = transcriptionText.substring(confirmedTextRef.current.trim().length);
                    console.log('ğŸ”„ æ£€æµ‹åˆ°é‡å ï¼Œåªæ·»åŠ æ–°å¢éƒ¨åˆ†:', textToAdd);
                  }
                  
                  if (textToAdd.trim()) {
                    setConfirmedText(prev => {
                      const newConfirmed = prev + textToAdd;
                      confirmedTextRef.current = newConfirmed; // ç«‹å³æ›´æ–°ref
                      console.log('ğŸ“ æ·»åŠ å®Œæ•´è½¬å½•æ–‡å­—:', textToAdd);
                      console.log('ğŸ“ æœ€ç»ˆç´¯ç§¯æ–‡å­—:', newConfirmed);
                      return newConfirmed;
                    });
                  }
                } else {
                  console.log('âš ï¸ å®Œæ•´è½¬å½•ä¸å·²ç¡®è®¤æ–‡å­—é‡å¤ï¼Œè·³è¿‡');
                }
                
                setRealtimeText('');
                realtimeTextRef.current = ''; // ç«‹å³æ›´æ–°ref
              }
            }
          }
        } catch (err) {
          console.error('âŒ WebSocketæ¶ˆæ¯è§£æå¤±è´¥:', err);
        }
      };
      
      ws.onerror = (error) => {
        console.error('âŒ WebSocketä»£ç†è¿æ¥é”™è¯¯:', error);
        throw new Error('WebSocketä»£ç†è¿æ¥å¤±è´¥');
      };
      
      ws.onclose = (event) => {
        console.log('ğŸ”Œ WebSocketä»£ç†è¿æ¥å·²å…³é—­, code:', event.code, 'reason:', event.reason);
        wsRef.current = null;
        setDashscopeReady(false);
        dashscopeReadyRef.current = false;
        currentTaskIdRef.current = '';
        // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ¸…ç©ºè¯†åˆ«å†…å®¹ï¼Œè®©stopRealtimeRecognitionæ¥å¤„ç†
      };
      
    } catch (err) {
      console.error('âŒ WebSocketå®æ—¶è¯†åˆ«å¯åŠ¨å¤±è´¥:', err);
      const errorMessage = err instanceof Error ? err.message : 'å®æ—¶è¯†åˆ«å¯åŠ¨å¤±è´¥';
      setError(errorMessage);
      throw err; // ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¸ä½¿ç”¨é™çº§æ–¹æ¡ˆ
    }
  };

  // å‘é€éŸ³é¢‘æ•°æ®åˆ°WebSocket
  const sendAudioToWebSocket = (audioData: ArrayBuffer) => {
    console.log('ğŸ” æ£€æŸ¥WebSocketçŠ¶æ€:', {
      wsExists: !!wsRef.current,
      wsState: wsRef.current?.readyState,
      dashscopeReady: dashscopeReady,
      dashscopeReadyRef: dashscopeReadyRef.current,
      audioSize: audioData.byteLength
    });
    
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      // æ£€æŸ¥DashScopeæ˜¯å¦å‡†å¤‡å¥½ï¼Œä½¿ç”¨refç¡®ä¿ç«‹å³å¯ç”¨
      if (dashscopeReadyRef.current) {
        try {
          // DashScopeå®æ—¶è¯†åˆ«åè®®ï¼šç›´æ¥å‘é€äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
          wsRef.current.send(audioData);
          console.log('âœ… æˆåŠŸå‘é€éŸ³é¢‘æ•°æ®åˆ°WebSocket:', audioData.byteLength, 'bytes');
        } catch (err) {
          console.error('âŒ å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', err);
          throw err; // ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¸ä½¿ç”¨é™çº§æ–¹æ¡ˆ
        }
      } else {
        console.log('â³ DashScopeæœªå‡†å¤‡å¥½ï¼Œè·³è¿‡éŸ³é¢‘æ•°æ®å‘é€');
      }      
    } else {
      console.error('âŒ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€éŸ³é¢‘æ•°æ®');
      throw new Error('WebSocketæœªè¿æ¥');
    }
  };

  // åœæ­¢å®æ—¶è¯†åˆ«
  const stopRealtimeRecognition = () => {
    console.log('ğŸ›‘ å¼€å§‹åœæ­¢WebSocketå®æ—¶è¯†åˆ«');
    console.log('ğŸ” stopRealtimeRecognitionå‡½æ•°å¼€å§‹æ—¶çŠ¶æ€:', {
      confirmedText: confirmedText,
      realtimeText: realtimeText,
      confirmedTextLength: confirmedText?.length || 0,
      realtimeTextLength: realtimeText?.length || 0
    });
    
    if (wsRef.current) {
      console.log('ğŸ›‘ WebSocketå­˜åœ¨ï¼Œå‘é€åœæ­¢æ¶ˆæ¯');
      
      // å‘é€DashScopeæ ‡å‡†ç»“æŸæ¶ˆæ¯
      const endMessage = {
        header: {
          action: 'finish-task',
          task_id: currentTaskIdRef.current
        },
        payload: {
          input: {
            audio_encoding: 'pcm',
            sample_rate: 16000,
            format: 'pcm'
          }
        }
      };
      
      try {
        wsRef.current.send(JSON.stringify(endMessage));
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æœåŠ¡å™¨å¤„ç†åœæ­¢æ¶ˆæ¯ï¼Œç„¶åå…³é—­è¿æ¥
        setTimeout(() => {
          if (wsRef.current) {
            wsRef.current.close();
            wsRef.current = null;
          }
        }, 1000);
        
        // ä¿å­˜è¯†åˆ«ç»“æœï¼ˆä¼˜å…ˆä½¿ç”¨confirmedTextï¼Œå¤‡ç”¨realtimeTextï¼‰
        // ä½¿ç”¨refè·å–æœ€æ–°å€¼ï¼Œé¿å…ReactçŠ¶æ€æ›´æ–°å»¶è¿Ÿ
        const currentConfirmedText = confirmedTextRef.current;
        const currentRealtimeText = realtimeTextRef.current;
        
        console.log('ğŸ” åœæ­¢å½•éŸ³æ—¶çŠ¶æ€æ£€æŸ¥:', {
          confirmedText: confirmedText,
          realtimeText: realtimeText,
          confirmedTextRef: currentConfirmedText,
          realtimeTextRef: currentRealtimeText,
          confirmedTextLength: currentConfirmedText.length,
          realtimeTextLength: currentRealtimeText.length,
          confirmedTextTrim: currentConfirmedText.trim(),
          realtimeTextTrim: currentRealtimeText.trim()
        });
        
        let finalText = '';
        if (currentConfirmedText.trim()) {
          finalText = currentConfirmedText.trim();
          console.log('âœ… ä½¿ç”¨å·²ç¡®è®¤è¯†åˆ«ç»“æœ:', finalText);
        } else if (currentRealtimeText.trim()) {
          // å®æ—¶æ–‡å­—ç°åœ¨å¯èƒ½åŒ…å«å®Œæ•´å†…å®¹ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦ä¸å·²ç¡®è®¤æ–‡å­—é‡å¤
          if (currentRealtimeText.trim() !== currentConfirmedText.trim()) {
            finalText = currentRealtimeText.trim();
            console.log('âš ï¸ æ²¡æœ‰ç¡®è®¤æ–‡å­—ï¼Œä½¿ç”¨æœ€åå®æ—¶è¯†åˆ«ç»“æœ:', finalText);
          } else {
            finalText = currentConfirmedText.trim();
            console.log('â„¹ï¸ å®æ—¶æ–‡å­—ä¸ç¡®è®¤æ–‡å­—ç›¸åŒï¼Œä½¿ç”¨ç¡®è®¤æ–‡å­—:', finalText);
          }
        } else {
          console.log('âš ï¸ æ²¡æœ‰ä»»ä½•è¯†åˆ«å†…å®¹');
        }
        
        setTranscriptText(finalText);
        if (finalText) {
          setConfidence(currentConfirmedText.trim() ? 0.95 : 0.8); // ç¡®è®¤æ–‡å­—ç½®ä¿¡åº¦é«˜ï¼Œå®æ—¶æ–‡å­—ç¨ä½
        }
        
        console.log('âœ… å½•éŸ³è¯†åˆ«æµç¨‹å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å¯¼å…¥ç¼–è¾‘å™¨');
        
        // æ— è®ºæ˜¯å¦æœ‰å†…å®¹ï¼Œéƒ½æ˜¾ç¤ºç»“æœæ¡†
        setShowResults(true);
        // æ¸…ç©ºå®æ—¶è¯†åˆ«çŠ¶æ€ï¼Œä½†ä¿ç•™æœ€ç»ˆç»“æœæ˜¾ç¤º
        setRealtimeText('');
        setConfirmedText('');
        // æ¸…ç©ºrefçŠ¶æ€
        confirmedTextRef.current = '';
        realtimeTextRef.current = '';
        setIsProcessing(false);
        setDashscopeReady(false);
        dashscopeReadyRef.current = false;
        currentTaskIdRef.current = '';
        
        // æ³¨æ„ï¼šä¸æ¸…ç©º transcriptTextï¼Œè®©ç»“æœæ¡†ä¿æŒæ˜¾ç¤º
        
      } catch (err) {
        console.error('âŒ åœæ­¢WebSocketè¯†åˆ«å¤±è´¥:', err);
        // å¼ºåˆ¶å…³é—­è¿æ¥
        if (wsRef.current) {
          wsRef.current.close();
          wsRef.current = null;
        }
        throw err; // ç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¸ä½¿ç”¨é™çº§æ–¹æ¡ˆ
      }
    }
  };

  // å¤„ç†å½•éŸ³å®Œæˆåçš„WebSocketå®æ—¶è¯†åˆ«ç»“æœ
  const processRealtimeAudio = async (audioBlob: Blob) => {
    try {
      console.log('ğŸ¤ å½•éŸ³å®Œæˆï¼Œå¤„ç†WebSocketå®æ—¶è¯†åˆ«ç»“æœ');
      console.log('ğŸ” è°ƒç”¨stopRealtimeRecognitionä¹‹å‰çŠ¶æ€:', {
        confirmedText: confirmedText,
        realtimeText: realtimeText,
        confirmedTextRef: confirmedTextRef.current,
        realtimeTextRef: realtimeTextRef.current,
        confirmedTextLength: confirmedText?.length || 0,
        realtimeTextLength: realtimeText?.length || 0,
        confirmedTextRefLength: confirmedTextRef.current?.length || 0,
        realtimeTextRefLength: realtimeTextRef.current?.length || 0
      });
      
      // åœæ­¢WebSocketè¿æ¥å¹¶ä¿å­˜ç»“æœ
      // stopRealtimeRecognitionå‡½æ•°å†…éƒ¨å·²ç»å¤„ç†äº†ç»“æœä¿å­˜
      stopRealtimeRecognition();
      
      console.log('âœ… WebSocketå®æ—¶è¯†åˆ«æµç¨‹å®Œæˆ');
      
    } catch (err) {
      console.error('å®æ—¶è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
      const errorMessage = err instanceof Error ? err.message : 'å®æ—¶è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•';
      setError(errorMessage);
      setIsProcessing(false);
    }
  };

  // å¤„ç†éŸ³é¢‘æ–‡ä»¶è¯†åˆ«
  const processFileAudio = async (audioBlob: Blob, model: string = 'sensevoice-v1') => {
    try {
      console.log(`ğŸ¤ å¼€å§‹å¤„ç†éŸ³é¢‘ï¼Œä½¿ç”¨${model}æ¨¡å‹...`);
      
      console.log('ğŸ“Š éŸ³é¢‘ä¿¡æ¯:', {
        originalSize: audioBlob.size,
        audioType: audioBlob.type,
        duration: recordingTime
      });
      
      // ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ éŸ³é¢‘åˆ°CloudBaseå­˜å‚¨
      console.log('ğŸ“¤ æ­£åœ¨ä¸Šä¼ éŸ³é¢‘åˆ°CloudBaseå­˜å‚¨...');
      const uploadResult = await storageService.uploadAudio(
        audioBlob, 
        'temp-user', // ä¸´æ—¶ç”¨æˆ·IDï¼Œå®é™…ä½¿ç”¨ä¸­åº”è¯¥è·å–çœŸå®ç”¨æˆ·ID
        'voice-recognition' // ç« èŠ‚ID
      );
      
      console.log('âœ… éŸ³é¢‘ä¸Šä¼ æˆåŠŸ:', uploadResult);
      
      // ç¬¬äºŒæ­¥ï¼šä½¿ç”¨éŸ³é¢‘URLè°ƒç”¨è¯­éŸ³è¯†åˆ«API
      console.log('ğŸ¤ è°ƒç”¨DashScopeæ–‡ä»¶è¯†åˆ«API...');
      
      const response = await fetch('/api/voice-recognition', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audioUrl: uploadResult.downloadUrl,
          recognitionType: 'file',
          uploadType: 'recording',
          duration: recordingTime.toString()
        })
      });
      
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || errorData.message || 'ç½‘ç»œè¯·æ±‚å¤±è´¥');
      }
      
      const result = await response.json();

      console.log('ğŸ“¡ DashScopeè¯­éŸ³è¯†åˆ«APIå“åº”:', result);
      
      if (!result.success) {
        const errorDetail = result.error || result.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥';
        console.error('âŒ DashScopeè¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯:', errorDetail);
        throw new Error(errorDetail);
      }

      const recognizedText = result.text;
      const confidenceScore = result.confidence || 0.95;
      
      console.log('âœ… DashScopeè¯­éŸ³è¯†åˆ«æˆåŠŸ:', recognizedText);
      console.log('ğŸ¯ ç½®ä¿¡åº¦:', confidenceScore);
      
      if (!recognizedText || recognizedText.trim().length === 0) {
        throw new Error('æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·é‡æ–°å½•åˆ¶');
      }
      
      setTranscriptText(recognizedText);
      setConfidence(confidenceScore);
      setIsProcessing(false);
      setRecordingTime(0);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
      try {
        await storageService.deleteFile(uploadResult.fileId);
        console.log('ğŸ—‘ï¸ ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å·²æ¸…ç†');
      } catch (cleanupError) {
        console.warn('âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
      }
      
    } catch (err) {
      console.error('DashScopeè¯­éŸ³è½¬æ¢å¤±è´¥:', err);
      const errorMessage = err instanceof Error ? err.message : 'DashScopeè¯­éŸ³è½¬æ¢å¤±è´¥ï¼Œè¯·é‡è¯•';
      setError(errorMessage);
      setIsProcessing(false);
    }
  };

  // å¤„ç†æ–‡ä»¶ä¸Šä¼ 
  const handleFileUpload = useCallback(async (file: File) => {
    try {
      setError('');
      setTranscriptText('');
      setConfidence(0);
      setRealtimeText('');
      setConfirmedText('');
      setShowResults(false);
      setIsUploading(true);
      setUploadProgress(0);

      // éªŒè¯æ–‡ä»¶ç±»å‹
      const allowedTypes = ['audio/wav', 'audio/mp3', 'audio/mpeg', 'audio/webm', 'audio/ogg'];
      if (!allowedTypes.includes(file.type) && !file.name.match(/\.(wav|mp3|mpeg|webm|ogg)$/i)) {
        throw new Error('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  WAVã€MP3ã€WEBM æˆ– OGG æ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶');
      }

      // éªŒè¯æ–‡ä»¶å¤§å° (é™åˆ¶ä¸º50MB)
      if (file.size > 50 * 1024 * 1024) {
        throw new Error('æ–‡ä»¶å¤ªå¤§ï¼Œè¯·ä¸Šä¼ å°äº50MBçš„éŸ³é¢‘æ–‡ä»¶');
      }

      console.log('ğŸ“ å¼€å§‹å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶:', {
        name: file.name,
        size: file.size,
        type: file.type
      });

      setUploadProgress(30);

      // ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ éŸ³é¢‘åˆ°CloudBaseå­˜å‚¨
      console.log('ğŸ“¤ æ­£åœ¨ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åˆ°CloudBaseå­˜å‚¨...');
      const audioBlob = new Blob([file], { type: file.type });
      const uploadResult = await storageService.uploadAudio(
        audioBlob, 
        'temp-user', // ä¸´æ—¶ç”¨æˆ·IDï¼Œå®é™…ä½¿ç”¨ä¸­åº”è¯¥è·å–çœŸå®ç”¨æˆ·ID
        'voice-recognition' // ç« èŠ‚ID
      );
      
      console.log('âœ… éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ æˆåŠŸ:', uploadResult);
      setUploadProgress(50);

      // ç¬¬äºŒæ­¥ï¼šä½¿ç”¨éŸ³é¢‘URLè°ƒç”¨è¯­éŸ³è¯†åˆ«API
      console.log('ğŸ“ è°ƒç”¨DashScopeæ–‡ä»¶è¯­éŸ³è¯†åˆ«APIå¤„ç†æ–‡ä»¶ä¸Šä¼ ...');
      
      const response = await fetch('/api/voice-recognition', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audioUrl: uploadResult.downloadUrl,
          recognitionType: 'file', // æ–‡ä»¶ä¸Šä¼ ä½¿ç”¨æ–‡ä»¶è¯†åˆ«
          uploadType: 'file',
          duration: '0'
        })
      });
      
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || errorData.message || 'ç½‘ç»œè¯·æ±‚å¤±è´¥');
      }
      
      const result = await response.json();

      setUploadProgress(80);

      console.log('ğŸ“¡ æ–‡ä»¶ä¸Šä¼ APIå“åº”:', result);
      
      if (!result.success) {
        throw new Error(result.error || result.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥');
      }

      console.log('âœ… æ–‡ä»¶ä¸Šä¼ è¯­éŸ³è¯†åˆ«æˆåŠŸ:', result.text);
      setUploadProgress(100);
      
      setTranscriptText(result.text);
      setConfidence(result.confidence || 0.95);
      setShowResults(true);
      
      console.log('âœ… æ–‡ä»¶è¯†åˆ«å®Œæˆï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å¯¼å…¥ç¼–è¾‘å™¨');
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
      try {
        await storageService.deleteFile(uploadResult.fileId);
        console.log('ğŸ—‘ï¸ ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å·²æ¸…ç†');
      } catch (cleanupError) {
        console.warn('âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
      }
      
      // é‡ç½®çŠ¶æ€
      setIsUploading(false);
      setUploadProgress(0);
      
    } catch (err) {
      console.error('æ–‡ä»¶ä¸Šä¼ å¤„ç†å¤±è´¥:', err);
      const errorMessage = err instanceof Error ? err.message : 'æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•';
      setError(errorMessage);
      setIsUploading(false);
      setUploadProgress(0);
    }
  }, []);

  // è§¦å‘æ–‡ä»¶é€‰æ‹©
  const triggerFileUpload = useCallback(() => {
    fileInputRef.current?.click();
  }, []);

  // æ–‡ä»¶é€‰æ‹©å¤„ç†
  const handleFileChange = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      handleFileUpload(file);
    }
    // æ¸…ç©ºinputå€¼ï¼Œå…è®¸é‡å¤ä¸Šä¼ åŒä¸€æ–‡ä»¶
    if (event.target) {
      event.target.value = '';
    }
  }, [handleFileUpload]);

  // å¯¼å…¥ç¼–è¾‘å™¨
  const handleImportToEditor = useCallback(() => {
    if (transcriptText.trim()) {
      onTranscriptionComplete(transcriptText.trim());
      setTranscriptText('');
      setConfidence(0);
      setError('');
      setShowResults(false);
      console.log('ğŸ“ ä¸“ä¸šè¯†åˆ«æ–‡æœ¬å·²æ‰‹åŠ¨å¯¼å…¥ç¼–è¾‘å™¨');
    }
  }, [transcriptText, onTranscriptionComplete]);

  // æ¸…ç©ºæ–‡æœ¬
  const handleClearText = useCallback(() => {
    setTranscriptText('');
    setConfidence(0);
    setError('');
    setRealtimeText('');
    setConfirmedText('');
    setShowResults(false);
  }, []);

  const formatTime = (seconds: number): string => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  return (
    <div className={cn('space-y-4 p-4 border rounded-lg bg-purple-50', className)}>
      {/* æ ‡é¢˜ */}
      <div className="text-center">
        <h3 className="text-lg font-semibold text-purple-700 mb-1">ä¸“ä¸šè¯­éŸ³è½¬æ–‡å­—</h3>
        <p className="text-sm text-purple-600">DashScopeè¯­éŸ³è¯†åˆ« â€¢ WebSocketä»£ç†å®æ—¶è¯†åˆ«+æ–‡ä»¶è¯†åˆ« â€¢ æ— é™çº§æ–¹æ¡ˆ</p>
      </div>

      {/* æ§åˆ¶æŒ‰é’® */}
      <div className="flex items-center justify-center space-x-3 flex-wrap gap-2">
        {!isRecording ? (
          <>
            <Button
              onClick={startRecording}
              disabled={isProcessing || isUploading}
              className="flex items-center space-x-2 bg-purple-600 hover:bg-purple-700"
            >
              <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
              </svg>
              <span>{isProcessing ? 'å¤„ç†ä¸­...' : 'å¼€å§‹å½•éŸ³'}</span>
            </Button>
            
            <Button
              onClick={triggerFileUpload}
              disabled={isProcessing || isUploading}
              variant="outline"
              className="flex items-center space-x-2 border-purple-300 text-purple-700 hover:bg-purple-100"
            >
              <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
                <path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"/>
              </svg>
              <span>{isUploading ? 'ä¸Šä¼ ä¸­...' : 'ä¸Šä¼ æ–‡ä»¶'}</span>
            </Button>
          </>
        ) : (
          <Button
            onClick={stopRecording}
            variant="destructive"
            className="flex items-center space-x-2"
          >
            <svg className="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
              <path d="M6 6h12v12H6z"/>
            </svg>
            <span>åœæ­¢å½•éŸ³</span>
          </Button>
        )}
        
        {(isRecording || isProcessing || isUploading) && (
          <div className="flex items-center space-x-2">
            <div className={cn(
              'w-3 h-3 rounded-full',
              isRecording ? 'bg-red-500 animate-pulse' : 
              isUploading ? 'bg-blue-500 animate-pulse' : 'bg-yellow-500'
            )} />
            <span className="text-sm text-gray-600">
              {isRecording ? `å½•éŸ³ä¸­ ${formatTime(recordingTime)}` : 
               isUploading ? `ä¸Šä¼ ä¸­ ${uploadProgress}%` : 'è½¬æ¢ä¸­...'}
            </span>
          </div>
        )}
      </div>

      {/* éšè—çš„æ–‡ä»¶è¾“å…¥ */}
      <input
        ref={fileInputRef}
        type="file"
        accept="audio/wav,audio/mp3,audio/mpeg,audio/webm,audio/ogg,.wav,.mp3,.mpeg,.webm,.ogg"
        onChange={handleFileChange}
        style={{ display: 'none' }}
      />
      
      {/* ä¸Šä¼ è¿›åº¦æ¡ */}
      {isUploading && uploadProgress > 0 && (
        <div className="w-full bg-gray-200 rounded-full h-2">
          <div 
            className="bg-purple-600 h-2 rounded-full transition-all duration-300" 
            style={{ width: `${uploadProgress}%` }}
          />
        </div>
      )}

      {/* å®æ—¶è¯†åˆ«æ–‡æœ¬æ˜¾ç¤º */}
      {isRecording && (confirmedText || realtimeText) && (
        <div className="bg-blue-50 p-3 rounded-lg border border-blue-200">
          <div className="text-sm text-blue-600 mb-1 flex items-center">
            <div className="w-2 h-2 bg-blue-500 rounded-full animate-pulse mr-2"></div>
            å®æ—¶è¯†åˆ«ï¼š
          </div>
          <div className="text-gray-900 text-sm leading-relaxed space-y-1">
            {/* å·²ç¡®è®¤çš„æ–‡å­—ï¼ˆä¸ä¼šè¢«ä¿®æ”¹ï¼‰ */}
            {confirmedText && (
              <div className="text-gray-800 font-medium">
                {confirmedText}
              </div>
            )}
            {/* å½“å‰æ­£åœ¨è¯†åˆ«çš„æ–‡å­—ï¼ˆå¯èƒ½è¢«ä¿®æ­£ï¼‰ */}
            {realtimeText && (
              <div className="text-gray-600 italic">
                {realtimeText}
              </div>
            )}
          </div>
        </div>
      )}

      {/* è¯†åˆ«ç»“æœæ˜¾ç¤º */}
      {showResults && (
        <div className="space-y-3">
          <div className="bg-white p-4 rounded-lg border">
            <div className="flex items-center justify-between mb-2">
              <div className="text-sm text-gray-500">è¯†åˆ«ç»“æœï¼š</div>
              {confidence > 0 && (
                <div className="text-xs text-green-600">
                  ç½®ä¿¡åº¦: {(confidence * 100).toFixed(1)}%
                </div>
              )}
            </div>
            <textarea
              value={transcriptText}
              onChange={(e) => setTranscriptText(e.target.value)}
              className="w-full text-gray-900 leading-relaxed resize-none border-0 bg-transparent focus:outline-none min-h-[80px]"
              placeholder="è¯†åˆ«ç»“æœå°†æ˜¾ç¤ºåœ¨æ­¤å¤„ï¼Œæ‚¨å¯ä»¥ç¼–è¾‘ä¿®æ”¹..."
            />
          </div>
          
          {/* æ“ä½œæŒ‰é’® */}
          <div className="flex items-center space-x-2">
            <Button
              onClick={handleImportToEditor}
              size="sm"
              className="bg-green-600 hover:bg-green-700"
            >
              <svg className="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 24 24">
                <path d="M19 13h-6v6h-2v-6H5v-2h6V5h2v6h6v2z"/>
              </svg>
              å¯¼å…¥ç¼–è¾‘å™¨
            </Button>
            
            <Button
              onClick={handleClearText}
              variant="outline"
              size="sm"
            >
              æ¸…ç©ºæ–‡æœ¬
            </Button>
          </div>
        </div>
      )}

      {/* é”™è¯¯ä¿¡æ¯ */}
      {error && (
        <div className="text-red-600 text-sm bg-red-50 p-3 rounded border">
          {error}
        </div>
      )}

      {/* ä½¿ç”¨è¯´æ˜ */}
      <div className="text-xs text-purple-600 space-y-1">
        <div>
          â€¢ <strong>åŒæ¨¡å¼è¯†åˆ«</strong>ï¼šå½•éŸ³ä½¿ç”¨WebSocketä»£ç†å®æ—¶è¯†åˆ«ï¼›æ–‡ä»¶ä¸Šä¼ ä½¿ç”¨å¼‚æ­¥è¯†åˆ«
        </div>
        <div>
          â€¢ <strong>é«˜ç²¾åº¦è¯†åˆ«</strong>ï¼šDashScopeè¯­éŸ³è¯†åˆ«å¼•æ“ï¼Œå‡†ç¡®ç‡å¯è¾¾95%ä»¥ä¸Š
        </div>
        <div>
          â€¢ <strong>æ”¯æŒé•¿éŸ³é¢‘</strong>ï¼šå½•éŸ³æ¨¡å¼æ”¯æŒé•¿æ—¶é—´å½•åˆ¶ï¼Œæ–‡ä»¶æ¨¡å¼æ”¯æŒå¤§æ–‡ä»¶(50MB)
        </div>
        <div>
          â€¢ <strong>æ™ºèƒ½ä¼˜åŒ–</strong>ï¼šæ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«ï¼Œè‡ªåŠ¨æ ‡ç‚¹ç¬¦å·é¢„æµ‹
        </div>
      </div>
    </div>
  );
}